{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import os\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from file\n",
    "\n",
    "#Read training data\n",
    "DATA_PATH = os.path.join('..','data') # use '..' to go up one directory level\n",
    "SOURCE = ''\n",
    "NAME = 'augmented_beos.csv'\n",
    "training_data = pd.read_csv(os.path.join(DATA_PATH, SOURCE, NAME)).dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking the data\n",
    "class_count = training_data['diseases'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode the label\n",
    "# label_encoder = LabelEncoder()\n",
    "# training_data['diseases'] = label_encoder.fit_transform(training_data['diseases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = class_count.max()\n",
    "balance_size = max_class\n",
    "for disease in class_count.index:\n",
    "    if class_count[disease] < balance_size:\n",
    "        # new samples random drop a value 1 to 0\n",
    "        new_samples = training_data[training_data['diseases'] == disease][:].sample(n=balance_size - class_count[disease], replace=True)\n",
    "        num_to_flip = random.randint(1,class_count[disease])\n",
    "        ones_indices = np.argwhere(new_samples.values == 1)\n",
    "        indices_to_flip = ones_indices[np.random.choice(ones_indices.shape[0], size=num_to_flip, replace=True)]\n",
    "        for index in indices_to_flip:\n",
    "            new_samples.iat[index[0], index[1]] = 0\n",
    "        training_data = pd.concat([training_data[:], new_samples[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv(\"../data/augmented_beos.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (280572, 377)\n",
      "X_test shape:  (70143, 377)\n",
      "y_train shape:  (280572,)\n",
      "y_test shape:  (70143,)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(training_data, test_size=0.2, random_state=42, stratify=training_data['diseases'])\n",
    "\n",
    "X_train = train_df.drop(columns=['diseases'])\n",
    "y_train = train_df['diseases']\n",
    "X_test = test_df.drop(columns=['diseases'])\n",
    "y_test = test_df['diseases']\n",
    "print(\"X_train shape: \", X_train.shape) \n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = pd.get_dummies(y_train[:])[:]\n",
    "y_test_ohe = pd.get_dummies(y_test[:])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train_ohe_tensor = torch.tensor(y_train_ohe.values, dtype=torch.float32)\n",
    "y_test_ohe_tensor = torch.tensor(y_test_ohe.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tensor = TensorDataset(X_train_tensor, y_train_ohe_tensor)\n",
    "testing_tensor = TensorDataset(X_test_tensor, y_test_ohe_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "training_loader = DataLoader(training_tensor, batch_size, shuffle=True)\n",
    "testing_loader = DataLoader(testing_tensor, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ANN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(X_train_tensor.shape[1], 1024)\n",
    "        self.fc2 = torch.nn.Linear(1024, 2048)\n",
    "        self.fc3 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc4 = torch.nn.Linear(1024,773)\n",
    "        # self.fc5 = torch.nn.Linear(1024, 773)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    accuracy = 0\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Compute the accuracy\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        correct = (predicted == torch.argmax(labels, 1)).sum().item()\n",
    "        accuracy += correct\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss, accuracy / len(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10 to 6.6218791007995605\n",
      "accuracy: 0 to 0.01986128625472888\n",
      "Epoch: 0, Loss: 6.649628162384033, Acc: 0.0014372145854099538, Val_Loss: 6.6218791007995605, Val_Acc: 0.01986128625472888\n",
      "Epoch: 1, Loss: 6.621870994567871, Acc: 0.02020909154129674, Val_Loss: 6.551183223724365, Val_Acc: 0.01197982345523329\n",
      "Epoch: 2, Loss: 6.551131725311279, Acc: 0.011590440204918983, Val_Loss: 6.390519142150879, Val_Acc: 0.006546250278169275\n",
      "Epoch: 3, Loss: 6.390387058258057, Acc: 0.006119752428197223, Val_Loss: 6.195268154144287, Val_Acc: 0.005081225428380684\n",
      "Epoch: 4, Loss: 6.194941520690918, Acc: 0.004960708407705325, Val_Loss: 6.272689342498779, Val_Acc: 0.008827238335435058\n",
      "loss: 6.6218791007995605 to 6.205638408660889\n",
      "accuracy: 0.01986128625472888 to 0.08298716712410059\n",
      "Epoch: 5, Loss: 6.271790981292725, Acc: 0.008873641020885973, Val_Loss: 6.205638408660889, Val_Acc: 0.08298716712410059\n",
      "Epoch: 6, Loss: 6.204654693603516, Acc: 0.08298291569113794, Val_Loss: 6.098793029785156, Val_Acc: 0.047882204584229655\n",
      "Epoch: 7, Loss: 6.097972869873047, Acc: 0.047979786272282623, Val_Loss: 6.0616135597229, Val_Acc: 0.013815740672056969\n",
      "Epoch: 8, Loss: 6.060913562774658, Acc: 0.013806532372099492, Val_Loss: 6.05554723739624, Val_Acc: 0.010236629330168385\n",
      "Epoch: 9, Loss: 6.054874897003174, Acc: 0.010259857669394284, Val_Loss: 6.024635314941406, Val_Acc: 0.018340627549885025\n",
      "Epoch: 10, Loss: 6.023916721343994, Acc: 0.01822480817821461, Val_Loss: 5.9529547691345215, Val_Acc: 0.03807210147615162\n",
      "Epoch: 11, Loss: 5.952108860015869, Acc: 0.037585479496511275, Val_Loss: 5.853801250457764, Val_Acc: 0.06436837029893924\n",
      "Epoch: 12, Loss: 5.8527655601501465, Acc: 0.0645772966457266, Val_Loss: 5.75309419631958, Val_Acc: 0.07473481195756991\n",
      "Epoch: 13, Loss: 5.751838207244873, Acc: 0.07486033519553073, Val_Loss: 5.648983478546143, Val_Acc: 0.07836955715451376\n",
      "loss: 6.205638408660889 to 5.512387275695801\n",
      "accuracy: 0.08298716712410059 to 0.09687708626956457\n",
      "Epoch: 14, Loss: 5.647546291351318, Acc: 0.07946405804492454, Val_Loss: 5.512387275695801, Val_Acc: 0.09687708626956457\n",
      "loss: 5.512387275695801 to 5.3414459228515625\n",
      "accuracy: 0.09687708626956457 to 0.1175728803501224\n",
      "Epoch: 15, Loss: 5.510891437530518, Acc: 0.09736897007348339, Val_Loss: 5.3414459228515625, Val_Acc: 0.1175728803501224\n",
      "loss: 5.3414459228515625 to 5.146891117095947\n",
      "accuracy: 0.1175728803501224 to 0.15197314739262666\n",
      "Epoch: 16, Loss: 5.339948654174805, Acc: 0.11711444400658337, Val_Loss: 5.146891117095947, Val_Acc: 0.15197314739262666\n",
      "loss: 5.146891117095947 to 4.936924457550049\n",
      "accuracy: 0.15197314739262666 to 0.18730064535271865\n",
      "Epoch: 17, Loss: 5.145401954650879, Acc: 0.15263682514661908, Val_Loss: 4.936924457550049, Val_Acc: 0.18730064535271865\n",
      "loss: 4.936924457550049 to 4.717262268066406\n",
      "accuracy: 0.18730064535271865 to 0.18945182108152214\n",
      "Epoch: 18, Loss: 4.935428619384766, Acc: 0.18792739748255638, Val_Loss: 4.717262268066406, Val_Acc: 0.18945182108152214\n",
      "loss: 4.717262268066406 to 4.4944562911987305\n",
      "accuracy: 0.18945182108152214 to 0.19087975669460722\n",
      "Epoch: 19, Loss: 4.715656757354736, Acc: 0.1898004126196713, Val_Loss: 4.4944562911987305, Val_Acc: 0.19087975669460722\n",
      "loss: 4.4944562911987305 to 4.27581787109375\n",
      "accuracy: 0.19087975669460722 to 0.2114828276834063\n",
      "Epoch: 20, Loss: 4.49261474609375, Acc: 0.19080646282945826, Val_Loss: 4.27581787109375, Val_Acc: 0.2114828276834063\n",
      "loss: 4.27581787109375 to 4.061799049377441\n",
      "accuracy: 0.2114828276834063 to 0.2470699503004228\n",
      "Epoch: 21, Loss: 4.273617744445801, Acc: 0.211298361111755, Val_Loss: 4.061799049377441, Val_Acc: 0.2470699503004228\n",
      "loss: 4.061799049377441 to 3.8535585403442383\n",
      "accuracy: 0.2470699503004228 to 0.28351012536162007\n",
      "Epoch: 22, Loss: 4.059256076812744, Acc: 0.24583323674633162, Val_Loss: 3.8535585403442383, Val_Acc: 0.28351012536162007\n",
      "loss: 3.8535585403442383 to 3.651442289352417\n",
      "accuracy: 0.28351012536162007 to 0.31774349083895853\n",
      "Epoch: 23, Loss: 3.8508946895599365, Acc: 0.28530100373212175, Val_Loss: 3.651442289352417, Val_Acc: 0.31774349083895853\n",
      "loss: 3.651442289352417 to 3.4500768184661865\n",
      "accuracy: 0.31774349083895853 to 0.32734960314516726\n",
      "Epoch: 24, Loss: 3.649012804031372, Acc: 0.3185006606550917, Val_Loss: 3.4500768184661865, Val_Acc: 0.32734960314516726\n",
      "loss: 3.4500768184661865 to 3.2519216537475586\n",
      "accuracy: 0.32734960314516726 to 0.34873154810474\n",
      "Epoch: 25, Loss: 3.4482226371765137, Acc: 0.32789818957324, Val_Loss: 3.2519216537475586, Val_Acc: 0.34873154810474\n",
      "loss: 3.2519216537475586 to 3.0592901706695557\n",
      "accuracy: 0.34873154810474 to 0.3844670276685706\n",
      "Epoch: 26, Loss: 3.250234603881836, Acc: 0.35199703284730754, Val_Loss: 3.0592901706695557, Val_Acc: 0.3844670276685706\n",
      "loss: 3.0592901706695557 to 2.869666814804077\n",
      "accuracy: 0.3844670276685706 to 0.3966508419256732\n",
      "Epoch: 27, Loss: 3.057360887527466, Acc: 0.3855351306242611, Val_Loss: 2.869666814804077, Val_Acc: 0.3966508419256732\n",
      "loss: 2.869666814804077 to 2.6904213428497314\n",
      "accuracy: 0.3966508419256732 to 0.4274163637712336\n",
      "Epoch: 28, Loss: 2.86759352684021, Acc: 0.39799253575650806, Val_Loss: 2.6904213428497314, Val_Acc: 0.4274163637712336\n",
      "loss: 2.6904213428497314 to 2.525075912475586\n",
      "accuracy: 0.4274163637712336 to 0.43166308137378534\n",
      "Epoch: 29, Loss: 2.6886696815490723, Acc: 0.4299496974895107, Val_Loss: 2.525075912475586, Val_Acc: 0.43166308137378534\n",
      "loss: 2.525075912475586 to 2.3709094524383545\n",
      "accuracy: 0.43166308137378534 to 0.45949855351976854\n",
      "Epoch: 30, Loss: 2.523380756378174, Acc: 0.43256450079974035, Val_Loss: 2.3709094524383545, Val_Acc: 0.45949855351976854\n",
      "loss: 2.3709094524383545 to 2.2408483028411865\n",
      "accuracy: 0.45949855351976854 to 0.46986499517839925\n",
      "Epoch: 31, Loss: 2.3680288791656494, Acc: 0.46154060131203783, Val_Loss: 2.2408483028411865, Val_Acc: 0.46986499517839925\n",
      "loss: 2.2408483028411865 to 2.0981502532958984\n",
      "accuracy: 0.46986499517839925 to 0.4879274534530079\n",
      "Epoch: 32, Loss: 2.237102746963501, Acc: 0.4705765084957927, Val_Loss: 2.0981502532958984, Val_Acc: 0.4879274534530079\n",
      "loss: 2.0981502532958984 to 2.008239984512329\n",
      "accuracy: 0.4879274534530079 to 0.48833543505674654\n",
      "Epoch: 33, Loss: 2.093240261077881, Acc: 0.49023389508333526, Val_Loss: 2.008239984512329, Val_Acc: 0.48833543505674654\n",
      "loss: 2.008239984512329 to 1.887528657913208\n",
      "accuracy: 0.48833543505674654 to 0.5197685631629702\n",
      "Epoch: 34, Loss: 2.00681209564209, Acc: 0.48932056839518767, Val_Loss: 1.887528657913208, Val_Acc: 0.5197685631629702\n",
      "loss: 1.887528657913208 to 1.8203821182250977\n",
      "accuracy: 0.5197685631629702 to 0.5209368741191306\n",
      "Epoch: 35, Loss: 1.88282310962677, Acc: 0.5232527411391085, Val_Loss: 1.8203821182250977, Val_Acc: 0.5209368741191306\n",
      "loss: 1.8203821182250977 to 1.704177975654602\n",
      "accuracy: 0.5209368741191306 to 0.5502002818781989\n",
      "Epoch: 36, Loss: 1.8129587173461914, Acc: 0.5256960059343054, Val_Loss: 1.704177975654602, Val_Acc: 0.5502002818781989\n",
      "loss: 1.704177975654602 to 1.6179513931274414\n",
      "accuracy: 0.5502002818781989 to 0.5618648468214524\n",
      "Epoch: 37, Loss: 1.697849988937378, Acc: 0.5501981965275041, Val_Loss: 1.6179513931274414, Val_Acc: 0.5618648468214524\n",
      "loss: 1.6179513931274414 to 1.5204603672027588\n",
      "accuracy: 0.5618648468214524 to 0.5894777835472146\n",
      "Epoch: 38, Loss: 1.6111499071121216, Acc: 0.5642087206472102, Val_Loss: 1.5204603672027588, Val_Acc: 0.5894777835472146\n",
      "loss: 1.5204603672027588 to 1.4554197788238525\n",
      "accuracy: 0.5894777835472146 to 0.6063904754840146\n",
      "Epoch: 39, Loss: 1.5112159252166748, Acc: 0.593133823222606, Val_Loss: 1.4554197788238525, Val_Acc: 0.6063904754840146\n",
      "loss: 1.4554197788238525 to 1.370942234992981\n",
      "accuracy: 0.6063904754840146 to 0.6238409613530154\n",
      "Epoch: 40, Loss: 1.4453505277633667, Acc: 0.607862954635017, Val_Loss: 1.370942234992981, Val_Acc: 0.6238409613530154\n",
      "loss: 1.370942234992981 to 1.3161578178405762\n",
      "accuracy: 0.6238409613530154 to 0.6388064683628811\n",
      "Epoch: 41, Loss: 1.3602663278579712, Acc: 0.6277892394353137, Val_Loss: 1.3161578178405762, Val_Acc: 0.6388064683628811\n",
      "loss: 1.3161578178405762 to 1.2390210628509521\n",
      "accuracy: 0.6388064683628811 to 0.6558489726281433\n",
      "Epoch: 42, Loss: 1.303316354751587, Acc: 0.6410116136210853, Val_Loss: 1.2390210628509521, Val_Acc: 0.6558489726281433\n",
      "loss: 1.2390210628509521 to 1.18826162815094\n",
      "accuracy: 0.6558489726281433 to 0.6679215191751354\n",
      "Epoch: 43, Loss: 1.2257753610610962, Acc: 0.6610352581191034, Val_Loss: 1.18826162815094, Val_Acc: 0.6679215191751354\n",
      "loss: 1.18826162815094 to 1.1228176355361938\n",
      "accuracy: 0.6679215191751354 to 0.6872450114976634\n",
      "Epoch: 44, Loss: 1.1742092370986938, Acc: 0.6731866756299404, Val_Loss: 1.1228176355361938, Val_Acc: 0.6872450114976634\n",
      "loss: 1.1228176355361938 to 1.0727015733718872\n",
      "accuracy: 0.6872450114976634 to 0.6981307024701432\n",
      "Epoch: 45, Loss: 1.1086333990097046, Acc: 0.6921254549247781, Val_Loss: 1.0727015733718872, Val_Acc: 0.6981307024701432\n",
      "loss: 1.0727015733718872 to 1.0078691244125366\n",
      "accuracy: 0.6981307024701432 to 0.7180847118166308\n",
      "Epoch: 46, Loss: 1.059326410293579, Acc: 0.7024363105310739, Val_Loss: 1.0078691244125366, Val_Acc: 0.7180847118166308\n",
      "loss: 1.0078691244125366 to 0.97472083568573\n",
      "accuracy: 0.7180847118166308 to 0.722071804762258\n",
      "Epoch: 47, Loss: 0.9933483600616455, Acc: 0.7207260251744362, Val_Loss: 0.97472083568573, Val_Acc: 0.722071804762258\n",
      "loss: 0.97472083568573 to 0.9269292950630188\n",
      "accuracy: 0.722071804762258 to 0.7343668867294711\n",
      "Epoch: 48, Loss: 0.9595972895622253, Acc: 0.7269153202438629, Val_Loss: 0.9269292950630188, Val_Acc: 0.7343668867294711\n",
      "loss: 0.9269292950630188 to 0.8883495330810547\n",
      "accuracy: 0.7343668867294711 to 0.7417291002151176\n",
      "Epoch: 49, Loss: 0.9099111557006836, Acc: 0.739780708871323, Val_Loss: 0.8883495330810547, Val_Acc: 0.7417291002151176\n",
      "loss: 0.8883495330810547 to 0.8519585728645325\n",
      "accuracy: 0.7417291002151176 to 0.7553223054669534\n",
      "Epoch: 50, Loss: 0.8695884346961975, Acc: 0.7485987157792253, Val_Loss: 0.8519585728645325, Val_Acc: 0.7553223054669534\n",
      "loss: 0.8519585728645325 to 0.8180481791496277\n",
      "accuracy: 0.7553223054669534 to 0.7623321712039166\n",
      "Epoch: 51, Loss: 0.8346691131591797, Acc: 0.7611952061939312, Val_Loss: 0.8180481791496277, Val_Acc: 0.7623321712039166\n",
      "loss: 0.8180481791496277 to 0.7809128165245056\n",
      "accuracy: 0.7623321712039166 to 0.7714932126696833\n",
      "Epoch: 52, Loss: 0.7999227643013, Acc: 0.7676163100674563, Val_Loss: 0.7809128165245056, Val_Acc: 0.7714932126696833\n",
      "loss: 0.7809128165245056 to 0.7556231021881104\n",
      "accuracy: 0.7714932126696833 to 0.7769267858467472\n",
      "Epoch: 53, Loss: 0.7633398771286011, Acc: 0.7760958761213751, Val_Loss: 0.7556231021881104, Val_Acc: 0.7769267858467472\n",
      "loss: 0.7556231021881104 to 0.7262209057807922\n",
      "accuracy: 0.7769267858467472 to 0.7850122394481122\n",
      "Epoch: 54, Loss: 0.7374106645584106, Acc: 0.7820023644498018, Val_Loss: 0.7262209057807922, Val_Acc: 0.7850122394481122\n",
      "loss: 0.7262209057807922 to 0.6995382308959961\n",
      "accuracy: 0.7850122394481122 to 0.7924486314071656\n",
      "Epoch: 55, Loss: 0.7076512575149536, Acc: 0.790417024038573, Val_Loss: 0.6995382308959961, Val_Acc: 0.7924486314071656\n",
      "loss: 0.6995382308959961 to 0.6821060180664062\n",
      "accuracy: 0.7924486314071656 to 0.7950077887397078\n",
      "Epoch: 56, Loss: 0.6821966767311096, Acc: 0.7967454043904587, Val_Loss: 0.6821060180664062, Val_Acc: 0.7950077887397078\n",
      "loss: 0.6821060180664062 to 0.6557160019874573\n",
      "accuracy: 0.7950077887397078 to 0.800645352718641\n",
      "Epoch: 57, Loss: 0.661237359046936, Acc: 0.8010941375553443, Val_Loss: 0.6557160019874573, Val_Acc: 0.800645352718641\n",
      "loss: 0.6557160019874573 to 0.6362480521202087\n",
      "accuracy: 0.800645352718641 to 0.8035383131815147\n",
      "Epoch: 58, Loss: 0.6353826522827148, Acc: 0.8060641183152136, Val_Loss: 0.6362480521202087, Val_Acc: 0.8035383131815147\n",
      "loss: 0.6362480521202087 to 0.6152356863021851\n",
      "accuracy: 0.8035383131815147 to 0.8077850307840665\n",
      "Epoch: 59, Loss: 0.6162737011909485, Acc: 0.8099816871044763, Val_Loss: 0.6152356863021851, Val_Acc: 0.8077850307840665\n",
      "loss: 0.6152356863021851 to 0.602281928062439\n",
      "accuracy: 0.8077850307840665 to 0.8105110896817743\n",
      "Epoch: 60, Loss: 0.5945946574211121, Acc: 0.814033705000116, Val_Loss: 0.602281928062439, Val_Acc: 0.8105110896817743\n",
      "loss: 0.602281928062439 to 0.5832834839820862\n",
      "accuracy: 0.8105110896817743 to 0.8160930198056524\n",
      "Epoch: 61, Loss: 0.5825833678245544, Acc: 0.8166021465495259, Val_Loss: 0.5832834839820862, Val_Acc: 0.8160930198056524\n",
      "loss: 0.5832834839820862 to 0.5687344670295715\n",
      "accuracy: 0.8160930198056524 to 0.8182627401528076\n",
      "Epoch: 62, Loss: 0.5633918046951294, Acc: 0.8225781775191822, Val_Loss: 0.5687344670295715, Val_Acc: 0.8182627401528076\n",
      "loss: 0.5687344670295715 to 0.5543368458747864\n",
      "accuracy: 0.8182627401528076 to 0.8216193160744751\n",
      "Epoch: 63, Loss: 0.5486851334571838, Acc: 0.8256195090289529, Val_Loss: 0.5543368458747864, Val_Acc: 0.8216193160744751\n",
      "loss: 0.5543368458747864 to 0.5449361801147461\n",
      "accuracy: 0.8216193160744751 to 0.8218418514946962\n",
      "Epoch: 64, Loss: 0.5337961316108704, Acc: 0.8286562043626416, Val_Loss: 0.5449361801147461, Val_Acc: 0.8218418514946962\n",
      "loss: 0.5449361801147461 to 0.5323355197906494\n",
      "accuracy: 0.8218418514946962 to 0.8246606334841629\n",
      "Epoch: 65, Loss: 0.5235071778297424, Acc: 0.8296576183963467, Val_Loss: 0.5323355197906494, Val_Acc: 0.8246606334841629\n",
      "loss: 0.5323355197906494 to 0.5217964053153992\n",
      "accuracy: 0.8246606334841629 to 0.828202655589348\n",
      "Epoch: 66, Loss: 0.5123846530914307, Acc: 0.8310901968056746, Val_Loss: 0.5217964053153992, Val_Acc: 0.828202655589348\n",
      "loss: 0.5217964053153992 to 0.5146452188491821\n",
      "accuracy: 0.828202655589348 to 0.8291113418885839\n",
      "Epoch: 67, Loss: 0.5000653266906738, Acc: 0.8361204478546095, Val_Loss: 0.5146452188491821, Val_Acc: 0.8291113418885839\n",
      "loss: 0.5146452188491821 to 0.506176769733429\n",
      "accuracy: 0.8291113418885839 to 0.8294266004005637\n",
      "Epoch: 68, Loss: 0.4929554760456085, Acc: 0.8372516748186096, Val_Loss: 0.506176769733429, Val_Acc: 0.8294266004005637\n",
      "loss: 0.506176769733429 to 0.5006552934646606\n",
      "accuracy: 0.8294266004005637 to 0.8329500778873971\n",
      "Epoch: 69, Loss: 0.48477938771247864, Acc: 0.8379888268156425, Val_Loss: 0.5006552934646606, Val_Acc: 0.8329500778873971\n",
      "Epoch: 70, Loss: 0.4805642366409302, Acc: 0.8407288068800853, Val_Loss: 0.49666959047317505, Val_Acc: 0.8326348193754173\n",
      "loss: 0.5006552934646606 to 0.4903470277786255\n",
      "accuracy: 0.8329500778873971 to 0.8330057117424523\n",
      "Epoch: 71, Loss: 0.4758777618408203, Acc: 0.840042652819954, Val_Loss: 0.4903470277786255, Val_Acc: 0.8330057117424523\n",
      "loss: 0.4903470277786255 to 0.47937333583831787\n",
      "accuracy: 0.8330057117424523 to 0.8348972628143313\n",
      "Epoch: 72, Loss: 0.46861380338668823, Acc: 0.8420037553026264, Val_Loss: 0.47937333583831787, Val_Acc: 0.8348972628143313\n",
      "loss: 0.47937333583831787 to 0.4670986831188202\n",
      "accuracy: 0.8348972628143313 to 0.8377160448037979\n",
      "Epoch: 73, Loss: 0.45855337381362915, Acc: 0.8431164375622986, Val_Loss: 0.4670986831188202, Val_Acc: 0.8377160448037979\n",
      "loss: 0.4670986831188202 to 0.4602767825126648\n",
      "accuracy: 0.8377160448037979 to 0.8400712113344707\n",
      "Epoch: 74, Loss: 0.44548624753952026, Acc: 0.8479936948005286, Val_Loss: 0.4602767825126648, Val_Acc: 0.8400712113344707\n",
      "Epoch: 75, Loss: 0.43840551376342773, Acc: 0.8495189967314959, Val_Loss: 0.457444429397583, Val_Acc: 0.8395890512573251\n",
      "loss: 0.4602767825126648 to 0.4566688537597656\n",
      "accuracy: 0.8400712113344707 to 0.8413507900007418\n",
      "Epoch: 76, Loss: 0.435997873544693, Acc: 0.8486891212128237, Val_Loss: 0.4566688537597656, Val_Acc: 0.8413507900007418\n",
      "loss: 0.4566688537597656 to 0.4494210183620453\n",
      "accuracy: 0.8413507900007418 to 0.8414620577108524\n",
      "Epoch: 77, Loss: 0.4343165159225464, Acc: 0.8500197037483483, Val_Loss: 0.4494210183620453, Val_Acc: 0.8414620577108524\n",
      "loss: 0.4494210183620453 to 0.4394010901451111\n",
      "accuracy: 0.8414620577108524 to 0.8452080706179067\n",
      "Epoch: 78, Loss: 0.42780980467796326, Acc: 0.8510442986624632, Val_Loss: 0.4394010901451111, Val_Acc: 0.8452080706179067\n",
      "Epoch: 79, Loss: 0.4176846146583557, Acc: 0.8541273557569716, Val_Loss: 0.43422579765319824, Val_Acc: 0.8450968029077962\n",
      "Epoch: 80, Loss: 0.4125322997570038, Acc: 0.855082408029857, Val_Loss: 0.4316323399543762, Val_Acc: 0.8450411690527408\n",
      "loss: 0.4394010901451111 to 0.4345002770423889\n",
      "accuracy: 0.8452080706179067 to 0.8474334248201172\n",
      "Epoch: 81, Loss: 0.41022196412086487, Acc: 0.8555460256380537, Val_Loss: 0.4345002770423889, Val_Acc: 0.8474334248201172\n",
      "Epoch: 82, Loss: 0.41100364923477173, Acc: 0.8555182085815619, Val_Loss: 0.42640015482902527, Val_Acc: 0.8468399970328611\n",
      "loss: 0.4345002770423889 to 0.41860824823379517\n",
      "accuracy: 0.8474334248201172 to 0.8481195756991321\n",
      "Epoch: 83, Loss: 0.40404197573661804, Acc: 0.8572475022601358, Val_Loss: 0.41860824823379517, Val_Acc: 0.8481195756991321\n",
      "loss: 0.41860824823379517 to 0.4157212972640991\n",
      "accuracy: 0.8481195756991321 to 0.8500111267710111\n",
      "Epoch: 84, Loss: 0.3959687352180481, Acc: 0.8592827835601197, Val_Loss: 0.4157212972640991, Val_Acc: 0.8500111267710111\n",
      "loss: 0.4157212972640991 to 0.4136081635951996\n",
      "accuracy: 0.8500111267710111 to 0.8503820191380461\n",
      "Epoch: 85, Loss: 0.39267849922180176, Acc: 0.8596073158858574, Val_Loss: 0.4136081635951996, Val_Acc: 0.8503820191380461\n",
      "loss: 0.4136081635951996 to 0.4127647876739502\n",
      "accuracy: 0.8503820191380461 to 0.8519212224612418\n",
      "Epoch: 86, Loss: 0.3917188346385956, Acc: 0.8599689376202508, Val_Loss: 0.4127647876739502, Val_Acc: 0.8519212224612418\n",
      "loss: 0.4127647876739502 to 0.40607330203056335\n",
      "accuracy: 0.8519212224612418 to 0.8525146502484979\n",
      "Epoch: 87, Loss: 0.3895066976547241, Acc: 0.8614339692621525, Val_Loss: 0.40607330203056335, Val_Acc: 0.8525146502484979\n",
      "loss: 0.40607330203056335 to 0.4024779200553894\n",
      "accuracy: 0.8525146502484979 to 0.8525702841035532\n",
      "Epoch: 88, Loss: 0.3831411898136139, Acc: 0.8627320985651035, Val_Loss: 0.4024779200553894, Val_Acc: 0.8525702841035532\n",
      "loss: 0.4024779200553894 to 0.4009135663509369\n",
      "accuracy: 0.8525702841035532 to 0.8549810844892812\n",
      "Epoch: 89, Loss: 0.37877827882766724, Acc: 0.8629639073692019, Val_Loss: 0.4009135663509369, Val_Acc: 0.8549810844892812\n",
      "Epoch: 90, Loss: 0.37733137607574463, Acc: 0.8644243028350217, Val_Loss: 0.39874792098999023, Val_Acc: 0.8539054966248795\n",
      "Epoch: 91, Loss: 0.37574827671051025, Acc: 0.8640348640441364, Val_Loss: 0.39773035049438477, Val_Acc: 0.8547956383057637\n",
      "loss: 0.4009135663509369 to 0.39170029759407043\n",
      "accuracy: 0.8549810844892812 to 0.8553890660930198\n",
      "Epoch: 92, Loss: 0.37379392981529236, Acc: 0.8647395628085954, Val_Loss: 0.39170029759407043, Val_Acc: 0.8553890660930198\n",
      "loss: 0.39170029759407043 to 0.39085566997528076\n",
      "accuracy: 0.8553890660930198 to 0.8567428232326979\n",
      "Epoch: 93, Loss: 0.3679956793785095, Acc: 0.866663575882612, Val_Loss: 0.39085566997528076, Val_Acc: 0.8567428232326979\n",
      "loss: 0.39085566997528076 to 0.38820406794548035\n",
      "accuracy: 0.8567428232326979 to 0.8569097247978636\n",
      "Epoch: 94, Loss: 0.3666473627090454, Acc: 0.8673682746470711, Val_Loss: 0.38820406794548035, Val_Acc: 0.8569097247978636\n",
      "Epoch: 95, Loss: 0.36383000016212463, Acc: 0.8673033681819236, Val_Loss: 0.3863461911678314, Val_Acc: 0.8567428232326979\n",
      "loss: 0.38820406794548035 to 0.38656866550445557\n",
      "accuracy: 0.8569097247978636 to 0.8582449373191899\n",
      "Epoch: 96, Loss: 0.36267027258872986, Acc: 0.8672060084842023, Val_Loss: 0.38656866550445557, Val_Acc: 0.8582449373191899\n",
      "Epoch: 97, Loss: 0.3613854944705963, Acc: 0.8678272560791859, Val_Loss: 0.3825075626373291, Val_Acc: 0.8580965803723759\n",
      "Epoch: 98, Loss: 0.35845956206321716, Acc: 0.8688379424650549, Val_Loss: 0.38151806592941284, Val_Acc: 0.8579482234255619\n",
      "loss: 0.38656866550445557 to 0.37964296340942383\n",
      "accuracy: 0.8582449373191899 to 0.8584860173577628\n",
      "Epoch: 99, Loss: 0.3561769127845764, Acc: 0.8693571941862351, Val_Loss: 0.37964296340942383, Val_Acc: 0.8584860173577628\n",
      "Epoch: 100, Loss: 0.35464438796043396, Acc: 0.8691578386147106, Val_Loss: 0.380525141954422, Val_Acc: 0.8581893034641347\n",
      "Epoch: 101, Loss: 0.35461992025375366, Acc: 0.8698254479705139, Val_Loss: 0.3822968900203705, Val_Acc: 0.8588198204880944\n",
      "Epoch: 102, Loss: 0.3572111129760742, Acc: 0.8685783166044646, Val_Loss: 0.3852823078632355, Val_Acc: 0.8543505674653216\n",
      "Epoch: 103, Loss: 0.358904093503952, Acc: 0.8668907485106284, Val_Loss: 0.3857414722442627, Val_Acc: 0.8573547956383057\n",
      "Epoch: 104, Loss: 0.3611319065093994, Acc: 0.8666079417696284, Val_Loss: 0.3878672122955322, Val_Acc: 0.854925450634226\n",
      "Epoch: 105, Loss: 0.36008498072624207, Acc: 0.866097962400612, Val_Loss: 0.3826513886451721, Val_Acc: 0.8581893034641347\n",
      "loss: 0.37964296340942383 to 0.37586429715156555\n",
      "accuracy: 0.8584860173577628 to 0.8588383651064461\n",
      "Epoch: 106, Loss: 0.3576589524745941, Acc: 0.8681796054614154, Val_Loss: 0.37586429715156555, Val_Acc: 0.8588383651064461\n",
      "Epoch: 107, Loss: 0.34866535663604736, Acc: 0.8709149493497763, Val_Loss: 0.36927419900894165, Val_Acc: 0.8578369557154514\n",
      "loss: 0.37586429715156555 to 0.3729003965854645\n",
      "accuracy: 0.8588383651064461 to 0.859672872932275\n",
      "Epoch: 108, Loss: 0.3429625332355499, Acc: 0.8711282134495468, Val_Loss: 0.3729003965854645, Val_Acc: 0.859672872932275\n",
      "Epoch: 109, Loss: 0.3458651900291443, Acc: 0.8709195855258582, Val_Loss: 0.3786759078502655, Val_Acc: 0.8557785030784066\n",
      "Epoch: 110, Loss: 0.35054025053977966, Acc: 0.8682862375113006, Val_Loss: 0.37640100717544556, Val_Acc: 0.8583376604109487\n",
      "Epoch: 111, Loss: 0.35080862045288086, Acc: 0.8689399383388581, Val_Loss: 0.37044671177864075, Val_Acc: 0.8590609005266672\n",
      "Epoch: 112, Loss: 0.3421071171760559, Acc: 0.871814367509678, Val_Loss: 0.3669984042644501, Val_Acc: 0.8591907128551295\n",
      "loss: 0.3729003965854645 to 0.37101835012435913\n",
      "accuracy: 0.859672872932275 to 0.8600993991543654\n",
      "Epoch: 113, Loss: 0.3391546308994293, Acc: 0.8712023922668582, Val_Loss: 0.37101835012435913, Val_Acc: 0.8600993991543654\n",
      "Epoch: 114, Loss: 0.34371232986450195, Acc: 0.8717030992837108, Val_Loss: 0.375353068113327, Val_Acc: 0.8572249833098435\n",
      "loss: 0.37101835012435913 to 0.3689732849597931\n",
      "accuracy: 0.8600993991543654 to 0.8601735776277725\n",
      "Epoch: 115, Loss: 0.346303254365921, Acc: 0.8699088991399894, Val_Loss: 0.3689732849597931, Val_Acc: 0.8601735776277725\n",
      "loss: 0.3689732849597931 to 0.3676537573337555\n",
      "accuracy: 0.8601735776277725 to 0.8605259253764558\n",
      "Epoch: 116, Loss: 0.3415539264678955, Acc: 0.8707248661304157, Val_Loss: 0.3676537573337555, Val_Acc: 0.8605259253764558\n",
      "Epoch: 117, Loss: 0.3385700285434723, Acc: 0.8728296900716289, Val_Loss: 0.371671199798584, Val_Acc: 0.8581522142274312\n",
      "Epoch: 118, Loss: 0.34318986535072327, Acc: 0.8700850738311041, Val_Loss: 0.37478628754615784, Val_Acc: 0.8579853126622654\n",
      "Epoch: 119, Loss: 0.3463827073574066, Acc: 0.8697419968010385, Val_Loss: 0.3700031042098999, Val_Acc: 0.8603775684296417\n",
      "Epoch: 120, Loss: 0.33960285782814026, Acc: 0.8731403138691207, Val_Loss: 0.3620888590812683, Val_Acc: 0.8603775684296417\n",
      "Epoch: 121, Loss: 0.33351606130599976, Acc: 0.8732793991515798, Val_Loss: 0.367840975522995, Val_Acc: 0.8601735776277725\n",
      "Epoch: 122, Loss: 0.33870092034339905, Acc: 0.8721528083636616, Val_Loss: 0.3658285439014435, Val_Acc: 0.8595430606038128\n",
      "loss: 0.3676537573337555 to 0.35985052585601807\n",
      "accuracy: 0.8605259253764558 to 0.8618055040427268\n",
      "Epoch: 123, Loss: 0.33556845784187317, Acc: 0.8739887340921209, Val_Loss: 0.35985052585601807, Val_Acc: 0.8618055040427268\n",
      "Epoch: 124, Loss: 0.3304268717765808, Acc: 0.8741834534875634, Val_Loss: 0.36134374141693115, Val_Acc: 0.8607855500333803\n",
      "Epoch: 125, Loss: 0.3314685821533203, Acc: 0.8745033496372192, Val_Loss: 0.36032548546791077, Val_Acc: 0.860581559231511\n",
      "loss: 0.35985052585601807 to 0.35649338364601135\n",
      "accuracy: 0.8618055040427268 to 0.8635116089310882\n",
      "Epoch: 126, Loss: 0.3301255702972412, Acc: 0.8735807505969077, Val_Loss: 0.35649338364601135, Val_Acc: 0.8635116089310882\n",
      "Epoch: 127, Loss: 0.3262978494167328, Acc: 0.875963745103039, Val_Loss: 0.35757777094841003, Val_Acc: 0.8615829686225057\n",
      "Epoch: 128, Loss: 0.3268580436706543, Acc: 0.8760471962725145, Val_Loss: 0.35425835847854614, Val_Acc: 0.8619724056078926\n",
      "Epoch: 129, Loss: 0.3233119249343872, Acc: 0.8760611048007604, Val_Loss: 0.3523336946964264, Val_Acc: 0.8633447073659224\n",
      "Epoch: 130, Loss: 0.32183384895324707, Acc: 0.876682352395744, Val_Loss: 0.3547646701335907, Val_Acc: 0.8620280394629478\n",
      "loss: 0.35649338364601135 to 0.3525802195072174\n",
      "accuracy: 0.8635116089310882 to 0.8640123136265856\n",
      "Epoch: 131, Loss: 0.323393851518631, Acc: 0.8764366350633997, Val_Loss: 0.3525802195072174, Val_Acc: 0.8640123136265856\n",
      "Epoch: 132, Loss: 0.3211595118045807, Acc: 0.8776698579012031, Val_Loss: 0.34812676906585693, Val_Acc: 0.8639566797715303\n",
      "Epoch: 133, Loss: 0.316964715719223, Acc: 0.8787269060478917, Val_Loss: 0.35008078813552856, Val_Acc: 0.8622876641198725\n",
      "Epoch: 134, Loss: 0.31857264041900635, Acc: 0.8771506061800227, Val_Loss: 0.35190463066101074, Val_Acc: 0.8638454120614197\n",
      "Epoch: 135, Loss: 0.3192996084690094, Acc: 0.877957300818285, Val_Loss: 0.34969383478164673, Val_Acc: 0.8638639566797716\n",
      "loss: 0.3525802195072174 to 0.3475556969642639\n",
      "accuracy: 0.8640123136265856 to 0.8641235813366961\n",
      "Epoch: 136, Loss: 0.3180055320262909, Acc: 0.8775724982034818, Val_Loss: 0.3475556969642639, Val_Acc: 0.8641235813366961\n",
      "Epoch: 137, Loss: 0.3163415491580963, Acc: 0.8780963861007441, Val_Loss: 0.35078319907188416, Val_Acc: 0.8620280394629478\n",
      "Epoch: 138, Loss: 0.31688153743743896, Acc: 0.8774519576253507, Val_Loss: 0.3474937081336975, Val_Acc: 0.8628069134337215\n",
      "Epoch: 139, Loss: 0.31515175104141235, Acc: 0.8784904610677113, Val_Loss: 0.3461327850818634, Val_Acc: 0.8636599658779023\n",
      "Epoch: 140, Loss: 0.3140290081501007, Acc: 0.8782308352071212, Val_Loss: 0.3471921980381012, Val_Acc: 0.8626214672502039\n",
      "loss: 0.3475556969642639 to 0.3453017473220825\n",
      "accuracy: 0.8641235813366961 to 0.8642163044284549\n",
      "Epoch: 141, Loss: 0.3130898177623749, Acc: 0.8789355339715802, Val_Loss: 0.3453017473220825, Val_Acc: 0.8642163044284549\n",
      "Epoch: 142, Loss: 0.31262120604515076, Acc: 0.8793435174667934, Val_Loss: 0.34602534770965576, Val_Acc: 0.8639752243898821\n",
      "Epoch: 143, Loss: 0.31294897198677063, Acc: 0.8789494424998261, Val_Loss: 0.34497228264808655, Val_Acc: 0.8636599658779023\n",
      "Epoch: 144, Loss: 0.3111731708049774, Acc: 0.8791997960082524, Val_Loss: 0.34413692355155945, Val_Acc: 0.8639937690082338\n",
      "loss: 0.3453017473220825 to 0.3428741693496704\n",
      "accuracy: 0.8642163044284549 to 0.8645130183220829\n",
      "Epoch: 145, Loss: 0.30979856848716736, Acc: 0.8799091309487934, Val_Loss: 0.3428741693496704, Val_Acc: 0.8645130183220829\n",
      "loss: 0.3428741693496704 to 0.34283509850502014\n",
      "accuracy: 0.8645130183220829 to 0.8650322676359321\n",
      "Epoch: 146, Loss: 0.30958160758018494, Acc: 0.8801223950485639, Val_Loss: 0.34283509850502014, Val_Acc: 0.8650322676359321\n",
      "Epoch: 147, Loss: 0.30865755677223206, Acc: 0.8799972182943508, Val_Loss: 0.34231168031692505, Val_Acc: 0.8645686521771382\n",
      "loss: 0.34283509850502014 to 0.3407217264175415\n",
      "accuracy: 0.8650322676359321 to 0.8651620799643943\n",
      "Epoch: 148, Loss: 0.30751481652259827, Acc: 0.8804422911982197, Val_Loss: 0.3407217264175415, Val_Acc: 0.8651620799643943\n",
      "Epoch: 149, Loss: 0.3068682849407196, Acc: 0.8804561997264656, Val_Loss: 0.3427041471004486, Val_Acc: 0.8645315629404347\n",
      "Epoch: 150, Loss: 0.3074895143508911, Acc: 0.8808734555738427, Val_Loss: 0.3404628038406372, Val_Acc: 0.8646057414138417\n",
      "Epoch: 151, Loss: 0.3058620095252991, Acc: 0.8812350773082361, Val_Loss: 0.3404006063938141, Val_Acc: 0.8645501075587865\n",
      "Epoch: 152, Loss: 0.30556413531303406, Acc: 0.8805581956002689, Val_Loss: 0.3418312966823578, Val_Acc: 0.8645871967954899\n",
      "Epoch: 153, Loss: 0.3062286972999573, Acc: 0.8815688819861378, Val_Loss: 0.33926087617874146, Val_Acc: 0.8644573844670277\n",
      "loss: 0.3407217264175415 to 0.3394284248352051\n",
      "accuracy: 0.8651620799643943 to 0.8653104369112083\n",
      "Epoch: 154, Loss: 0.30389583110809326, Acc: 0.881823871670646, Val_Loss: 0.3394284248352051, Val_Acc: 0.8653104369112083\n",
      "Epoch: 155, Loss: 0.30417415499687195, Acc: 0.8810403579127936, Val_Loss: 0.33989185094833374, Val_Acc: 0.8647170091239522\n",
      "Epoch: 156, Loss: 0.3037241995334625, Acc: 0.88183314402281, Val_Loss: 0.3382263779640198, Val_Acc: 0.8649395445441733\n",
      "Epoch: 157, Loss: 0.30239441990852356, Acc: 0.8822782169266788, Val_Loss: 0.33869054913520813, Val_Acc: 0.8650693568726355\n",
      "loss: 0.3394284248352051 to 0.3388224244117737\n",
      "accuracy: 0.8653104369112083 to 0.8665900155774794\n",
      "Epoch: 158, Loss: 0.3026846945285797, Acc: 0.8820046825378428, Val_Loss: 0.3388224244117737, Val_Acc: 0.8665900155774794\n",
      "Epoch: 159, Loss: 0.30266088247299194, Acc: 0.882542478963351, Val_Loss: 0.33992746472358704, Val_Acc: 0.8643646613752689\n",
      "Epoch: 160, Loss: 0.30267250537872314, Acc: 0.8813509817102854, Val_Loss: 0.3382093608379364, Val_Acc: 0.8654031600029671\n",
      "Epoch: 161, Loss: 0.30250614881515503, Acc: 0.8814529775840887, Val_Loss: 0.34034302830696106, Val_Acc: 0.8635672427861435\n",
      "Epoch: 162, Loss: 0.3027162253856659, Acc: 0.8817914184380723, Val_Loss: 0.3393182158470154, Val_Acc: 0.8650137230175803\n",
      "Epoch: 163, Loss: 0.30252891778945923, Acc: 0.8812860752451378, Val_Loss: 0.34041643142700195, Val_Acc: 0.8632705288925154\n",
      "Epoch: 164, Loss: 0.30308234691619873, Acc: 0.8805025614872853, Val_Loss: 0.34177660942077637, Val_Acc: 0.8653104369112083\n",
      "Epoch: 165, Loss: 0.3041384518146515, Acc: 0.8815827905143837, Val_Loss: 0.34020668268203735, Val_Acc: 0.864661375268897\n",
      "Epoch: 166, Loss: 0.30244213342666626, Acc: 0.8815642458100559, Val_Loss: 0.3386867344379425, Val_Acc: 0.8642348490468066\n",
      "Epoch: 167, Loss: 0.30126434564590454, Acc: 0.8808595470455968, Val_Loss: 0.33875054121017456, Val_Acc: 0.8639381351531785\n",
      "Epoch: 168, Loss: 0.3004014492034912, Acc: 0.8815642458100559, Val_Loss: 0.33707496523857117, Val_Acc: 0.8644388398486759\n",
      "Epoch: 169, Loss: 0.2986527979373932, Acc: 0.8830802753888592, Val_Loss: 0.33754962682724, Val_Acc: 0.8648653660707663\n",
      "Epoch: 170, Loss: 0.2995101809501648, Acc: 0.8821484039963838, Val_Loss: 0.33840492367744446, Val_Acc: 0.8637897782063645\n",
      "Epoch: 171, Loss: 0.2996130585670471, Acc: 0.8828160133521871, Val_Loss: 0.33663415908813477, Val_Acc: 0.8651064461093391\n",
      "Epoch: 172, Loss: 0.2980820834636688, Acc: 0.8824265745613018, Val_Loss: 0.33696359395980835, Val_Acc: 0.8640864920999926\n",
      "Epoch: 173, Loss: 0.29771193861961365, Acc: 0.882978279515056, Val_Loss: 0.3378553092479706, Val_Acc: 0.865940953935168\n",
      "Epoch: 174, Loss: 0.29902586340904236, Acc: 0.8827464707109576, Val_Loss: 0.3401203453540802, Val_Acc: 0.8625287441584453\n",
      "Epoch: 175, Loss: 0.30012640357017517, Acc: 0.881401979647187, Val_Loss: 0.3425242304801941, Val_Acc: 0.8633261627475707\n",
      "Epoch: 176, Loss: 0.3040774166584015, Acc: 0.8795938709752197, Val_Loss: 0.34806495904922485, Val_Acc: 0.8630850827089979\n",
      "Epoch: 177, Loss: 0.30737119913101196, Acc: 0.8796309603838753, Val_Loss: 0.34174153208732605, Val_Acc: 0.8633817966026259\n",
      "Epoch: 178, Loss: 0.3021903336048126, Acc: 0.8801641206333016, Val_Loss: 0.33823421597480774, Val_Acc: 0.8642533936651584\n",
      "Epoch: 179, Loss: 0.29821112751960754, Acc: 0.8820881337073182, Val_Loss: 0.3344191014766693, Val_Acc: 0.8651806245827461\n",
      "Epoch: 180, Loss: 0.29412195086479187, Acc: 0.8841744129442036, Val_Loss: 0.3341589570045471, Val_Acc: 0.8645871967954899\n",
      "Epoch: 181, Loss: 0.2938727140426636, Acc: 0.883404807714597, Val_Loss: 0.3367115259170532, Val_Acc: 0.8648653660707663\n",
      "Epoch: 182, Loss: 0.29577091336250305, Acc: 0.8828809198173346, Val_Loss: 0.33980390429496765, Val_Acc: 0.8652548030561531\n",
      "Epoch: 183, Loss: 0.3000754117965698, Acc: 0.8818655972553837, Val_Loss: 0.34181493520736694, Val_Acc: 0.8626214672502039\n",
      "Epoch: 184, Loss: 0.2999015748500824, Acc: 0.8818192354945641, Val_Loss: 0.3394488990306854, Val_Acc: 0.8642163044284549\n",
      "Epoch: 185, Loss: 0.29852765798568726, Acc: 0.8806462829458263, Val_Loss: 0.33706310391426086, Val_Acc: 0.8659038646984645\n",
      "Epoch: 186, Loss: 0.2960711419582367, Acc: 0.8833213565451216, Val_Loss: 0.3354952037334442, Val_Acc: 0.8650322676359321\n",
      "Epoch: 187, Loss: 0.29366615414619446, Acc: 0.8843969493961381, Val_Loss: 0.33928489685058594, Val_Acc: 0.8626029226318522\n",
      "Epoch: 188, Loss: 0.2980266809463501, Acc: 0.8811377176105148, Val_Loss: 0.33917567133903503, Val_Acc: 0.8646984645056005\n",
      "Epoch: 189, Loss: 0.2974205017089844, Acc: 0.8828160133521871, Val_Loss: 0.33849403262138367, Val_Acc: 0.8648653660707663\n",
      "Epoch: 190, Loss: 0.29697611927986145, Acc: 0.8823848489765641, Val_Loss: 0.3380425274372101, Val_Acc: 0.8623432979749277\n",
      "Epoch: 191, Loss: 0.29582569003105164, Acc: 0.8822272189897772, Val_Loss: 0.33828166127204895, Val_Acc: 0.8646057414138417\n",
      "Epoch: 192, Loss: 0.29555752873420715, Acc: 0.8829180092259904, Val_Loss: 0.3397270441055298, Val_Acc: 0.8659038646984645\n",
      "Epoch: 193, Loss: 0.29776373505592346, Acc: 0.8826120216045805, Val_Loss: 0.3364180326461792, Val_Acc: 0.8641235813366961\n",
      "Epoch: 194, Loss: 0.29380345344543457, Acc: 0.8830617306845314, Val_Loss: 0.3371073007583618, Val_Acc: 0.862398931829983\n",
      "Epoch: 195, Loss: 0.2942085862159729, Acc: 0.8825795683720068, Val_Loss: 0.3409958481788635, Val_Acc: 0.8647355537423039\n",
      "Epoch: 196, Loss: 0.2974538803100586, Acc: 0.8829272815781544, Val_Loss: 0.3398455083370209, Val_Acc: 0.8636043320228469\n",
      "Epoch: 197, Loss: 0.29704684019088745, Acc: 0.8805721041285148, Val_Loss: 0.33658722043037415, Val_Acc: 0.8625658333951487\n",
      "Epoch: 198, Loss: 0.2936153709888458, Acc: 0.8821762210528756, Val_Loss: 0.34011465311050415, Val_Acc: 0.8643461167569172\n",
      "Epoch: 199, Loss: 0.295725017786026, Acc: 0.8830478221562855, Val_Loss: 0.3379973769187927, Val_Acc: 0.8647540983606558\n",
      "Epoch: 200, Loss: 0.29518407583236694, Acc: 0.8817172396207608, Val_Loss: 0.33549764752388, Val_Acc: 0.8634930643127364\n",
      "Epoch: 201, Loss: 0.2922273278236389, Acc: 0.8831034562692691, Val_Loss: 0.34423819184303284, Val_Acc: 0.8638454120614197\n",
      "Epoch: 202, Loss: 0.2992752492427826, Acc: 0.8821205869398919, Val_Loss: 0.34195247292518616, Val_Acc: 0.8629738149988874\n",
      "Epoch: 203, Loss: 0.2979571521282196, Acc: 0.8815225202253182, Val_Loss: 0.34170421957969666, Val_Acc: 0.8648653660707663\n",
      "Epoch: 204, Loss: 0.2986346185207367, Acc: 0.8827881962956953, Val_Loss: 0.3414098024368286, Val_Acc: 0.8639195905348268\n",
      "Epoch: 205, Loss: 0.2959611713886261, Acc: 0.883265722432138, Val_Loss: 0.3365623354911804, Val_Acc: 0.8633817966026259\n",
      "Epoch: 206, Loss: 0.2917878031730652, Acc: 0.8830339136280396, Val_Loss: 0.33760419487953186, Val_Acc: 0.8644388398486759\n",
      "Epoch: 207, Loss: 0.29354071617126465, Acc: 0.8833538097776954, Val_Loss: 0.33554667234420776, Val_Acc: 0.8640679474816408\n",
      "Epoch: 208, Loss: 0.2901157736778259, Acc: 0.8842393194093512, Val_Loss: 0.33827006816864014, Val_Acc: 0.8634188858393295\n",
      "Epoch: 209, Loss: 0.2934345602989197, Acc: 0.8823106701592527, Val_Loss: 0.33981260657310486, Val_Acc: 0.863826867443068\n",
      "Epoch: 210, Loss: 0.29477518796920776, Acc: 0.8836180718143675, Val_Loss: 0.3368390202522278, Val_Acc: 0.8653104369112083\n",
      "Epoch: 211, Loss: 0.29195937514305115, Acc: 0.8848652031804168, Val_Loss: 0.3373233675956726, Val_Acc: 0.862695645723611\n",
      "Epoch: 212, Loss: 0.2913219630718231, Acc: 0.8829411901064003, Val_Loss: 0.3352762758731842, Val_Acc: 0.8638083228247163\n",
      "Epoch: 213, Loss: 0.2902459502220154, Acc: 0.8843134982266626, Val_Loss: 0.3356477916240692, Val_Acc: 0.8651620799643943\n",
      "Epoch: 214, Loss: 0.2901375889778137, Acc: 0.8853520016690234, Val_Loss: 0.3362222909927368, Val_Acc: 0.8639566797715303\n",
      "Epoch: 215, Loss: 0.28958725929260254, Acc: 0.88440158557222, Val_Loss: 0.3361148536205292, Val_Acc: 0.8643090275202137\n",
      "Epoch: 216, Loss: 0.29046183824539185, Acc: 0.8834558056514986, Val_Loss: 0.3362930417060852, Val_Acc: 0.8639752243898821\n",
      "Epoch: 217, Loss: 0.29019564390182495, Acc: 0.8837757018011544, Val_Loss: 0.33743390440940857, Val_Acc: 0.8639937690082338\n",
      "Epoch: 218, Loss: 0.2910500764846802, Acc: 0.8839982382530889, Val_Loss: 0.33541521430015564, Val_Acc: 0.8641235813366961\n",
      "Epoch: 219, Loss: 0.28908011317253113, Acc: 0.8835021674123184, Val_Loss: 0.3347819447517395, Val_Acc: 0.8645130183220829\n",
      "Epoch: 220, Loss: 0.28849467635154724, Acc: 0.8847585711305316, Val_Loss: 0.3359474241733551, Val_Acc: 0.8650508122542838\n",
      "Epoch: 221, Loss: 0.28877007961273193, Acc: 0.8846055773198266, Val_Loss: 0.3353666067123413, Val_Acc: 0.8631592611824048\n",
      "Epoch: 222, Loss: 0.28850269317626953, Acc: 0.8842022300006954, Val_Loss: 0.33694225549697876, Val_Acc: 0.8636228766411987\n",
      "Epoch: 223, Loss: 0.2898849844932556, Acc: 0.8843088620505807, Val_Loss: 0.3361591398715973, Val_Acc: 0.8635116089310882\n",
      "Epoch: 224, Loss: 0.2887773811817169, Acc: 0.8841929576485315, Val_Loss: 0.33356979489326477, Val_Acc: 0.8646799198872487\n",
      "Epoch: 225, Loss: 0.28601181507110596, Acc: 0.885416908134171, Val_Loss: 0.333631306886673, Val_Acc: 0.8632519842741636\n",
      "Epoch: 226, Loss: 0.2864254117012024, Acc: 0.8842856811701708, Val_Loss: 0.33759909868240356, Val_Acc: 0.8618425932794304\n",
      "Epoch: 227, Loss: 0.28979310393333435, Acc: 0.8831451818540068, Val_Loss: 0.3363623321056366, Val_Acc: 0.8664602032490172\n",
      "Epoch: 228, Loss: 0.28801342844963074, Acc: 0.8851665546257447, Val_Loss: 0.33560898900032043, Val_Acc: 0.863066538090646\n",
      "Epoch: 229, Loss: 0.2879873514175415, Acc: 0.883404807714597, Val_Loss: 0.334441214799881, Val_Acc: 0.8632148950374602\n",
      "Epoch: 230, Loss: 0.28612369298934937, Acc: 0.8839889659009249, Val_Loss: 0.3347105085849762, Val_Acc: 0.8635486981677917\n",
      "Epoch: 231, Loss: 0.28593942523002625, Acc: 0.8859268875031874, Val_Loss: 0.3388804495334625, Val_Acc: 0.8637897782063645\n",
      "Epoch: 232, Loss: 0.29061639308929443, Acc: 0.8832935394886298, Val_Loss: 0.33909204602241516, Val_Acc: 0.8631407165640531\n",
      "Epoch: 233, Loss: 0.29010990262031555, Acc: 0.8828623751130068, Val_Loss: 0.33614933490753174, Val_Acc: 0.8633076181292189\n",
      "Epoch: 234, Loss: 0.28769534826278687, Acc: 0.8844757643895315, Val_Loss: 0.33321988582611084, Val_Acc: 0.8655329723314295\n",
      "Epoch: 235, Loss: 0.28404155373573303, Acc: 0.8867196736132038, Val_Loss: 0.33517491817474365, Val_Acc: 0.864883910689118\n",
      "Epoch: 236, Loss: 0.2857745587825775, Acc: 0.885268550499548, Val_Loss: 0.3352045714855194, Val_Acc: 0.8624916549217417\n",
      "Epoch: 237, Loss: 0.2861706018447876, Acc: 0.8852917313799578, Val_Loss: 0.3354482352733612, Val_Acc: 0.8642904829018618\n",
      "Epoch: 238, Loss: 0.28554385900497437, Acc: 0.8861308792507939, Val_Loss: 0.3352545499801636, Val_Acc: 0.8646984645056005\n",
      "Epoch: 239, Loss: 0.2859381437301636, Acc: 0.8861123345464661, Val_Loss: 0.33194926381111145, Val_Acc: 0.8641977598101032\n",
      "Epoch: 240, Loss: 0.2817600965499878, Acc: 0.8864785924569415, Val_Loss: 0.3341005742549896, Val_Acc: 0.8642163044284549\n",
      "Epoch: 241, Loss: 0.2845609188079834, Acc: 0.8862050580681055, Val_Loss: 0.33694276213645935, Val_Acc: 0.8642533936651584\n",
      "Epoch: 242, Loss: 0.28677868843078613, Acc: 0.8847353902501217, Val_Loss: 0.33808082342147827, Val_Acc: 0.8641421259550478\n",
      "Epoch: 243, Loss: 0.2874959409236908, Acc: 0.8842532279375971, Val_Loss: 0.33258622884750366, Val_Acc: 0.8645315629404347\n",
      "Epoch: 244, Loss: 0.28281667828559875, Acc: 0.8862885092375808, Val_Loss: 0.32993853092193604, Val_Acc: 0.8655515169497812\n",
      "Epoch: 245, Loss: 0.27901193499565125, Acc: 0.8880966179095482, Val_Loss: 0.3347744941711426, Val_Acc: 0.8636599658779023\n",
      "Epoch: 246, Loss: 0.2838159203529358, Acc: 0.8853195484364497, Val_Loss: 0.33517199754714966, Val_Acc: 0.863678510496254\n",
      "Epoch: 247, Loss: 0.28473976254463196, Acc: 0.8855189040079742, Val_Loss: 0.3343915641307831, Val_Acc: 0.864661375268897\n",
      "Epoch: 248, Loss: 0.2834368944168091, Acc: 0.8866547671480562, Val_Loss: 0.3352504372596741, Val_Acc: 0.8632148950374602\n",
      "Epoch: 249, Loss: 0.28389298915863037, Acc: 0.8859176151510234, Val_Loss: 0.33336812257766724, Val_Acc: 0.8650693568726355\n",
      "Epoch: 250, Loss: 0.2815153896808624, Acc: 0.8871554741649088, Val_Loss: 0.3389073610305786, Val_Acc: 0.8634374304576812\n",
      "Epoch: 251, Loss: 0.2875259518623352, Acc: 0.8850089246389578, Val_Loss: 0.3361949622631073, Val_Acc: 0.8636414212595505\n",
      "Epoch: 252, Loss: 0.28500157594680786, Acc: 0.8847168455457939, Val_Loss: 0.3345353603363037, Val_Acc: 0.8653289815295602\n",
      "Epoch: 253, Loss: 0.28264787793159485, Acc: 0.8860057024965808, Val_Loss: 0.3358672559261322, Val_Acc: 0.8623803872116312\n",
      "Epoch: 254, Loss: 0.2840805649757385, Acc: 0.8855189040079742, Val_Loss: 0.3321928083896637, Val_Acc: 0.8645686521771382\n",
      "Epoch: 255, Loss: 0.2801135182380676, Acc: 0.8871554741649088, Val_Loss: 0.338209867477417, Val_Acc: 0.8639195905348268\n",
      "Epoch: 256, Loss: 0.285480260848999, Acc: 0.8846102134959086, Val_Loss: 0.3344002664089203, Val_Acc: 0.8644388398486759\n",
      "Epoch: 257, Loss: 0.28238630294799805, Acc: 0.8862977815897448, Val_Loss: 0.3306432068347931, Val_Acc: 0.8645130183220829\n",
      "Epoch: 258, Loss: 0.27797189354896545, Acc: 0.8883237905375646, Val_Loss: 0.33732783794403076, Val_Acc: 0.8640123136265856\n",
      "Epoch: 259, Loss: 0.28453972935676575, Acc: 0.8858805257423676, Val_Loss: 0.33280983567237854, Val_Acc: 0.8638454120614197\n",
      "Epoch: 260, Loss: 0.2802698016166687, Acc: 0.8865064095134333, Val_Loss: 0.3369867205619812, Val_Acc: 0.8625658333951487\n",
      "Epoch: 261, Loss: 0.2834015190601349, Acc: 0.8858666172141217, Val_Loss: 0.3386778235435486, Val_Acc: 0.8644944737037312\n",
      "Epoch: 262, Loss: 0.28619441390037537, Acc: 0.8859222513271054, Val_Loss: 0.3398863971233368, Val_Acc: 0.8617498701876716\n",
      "Epoch: 263, Loss: 0.28596019744873047, Acc: 0.8837154315120889, Val_Loss: 0.34161752462387085, Val_Acc: 0.8636228766411987\n",
      "Epoch: 264, Loss: 0.28787311911582947, Acc: 0.8851990078583185, Val_Loss: 0.33790090680122375, Val_Acc: 0.863066538090646\n",
      "Epoch: 265, Loss: 0.2841961681842804, Acc: 0.8848188414195971, Val_Loss: 0.3339162766933441, Val_Acc: 0.8634374304576812\n",
      "Epoch: 266, Loss: 0.2806471586227417, Acc: 0.8866130415633185, Val_Loss: 0.3320090174674988, Val_Acc: 0.8652733476745048\n",
      "Epoch: 267, Loss: 0.27791330218315125, Acc: 0.888416514059204, Val_Loss: 0.3363886773586273, Val_Acc: 0.8632148950374602\n",
      "Epoch: 268, Loss: 0.28179624676704407, Acc: 0.8862885092375808, Val_Loss: 0.33719122409820557, Val_Acc: 0.8632519842741636\n",
      "Epoch: 269, Loss: 0.2830278277397156, Acc: 0.8859639769118431, Val_Loss: 0.33525943756103516, Val_Acc: 0.8632705288925154\n",
      "Epoch: 270, Loss: 0.2804059684276581, Acc: 0.8861957857159415, Val_Loss: 0.3352249264717102, Val_Acc: 0.8654587938580224\n",
      "Epoch: 271, Loss: 0.28120604157447815, Acc: 0.8868216694870071, Val_Loss: 0.3348575830459595, Val_Acc: 0.8615087901490988\n",
      "Epoch: 272, Loss: 0.2796926498413086, Acc: 0.8862328751245973, Val_Loss: 0.3362968862056732, Val_Acc: 0.8623803872116312\n",
      "Epoch: 273, Loss: 0.28175580501556396, Acc: 0.8853473654929415, Val_Loss: 0.3384760916233063, Val_Acc: 0.8640864920999926\n",
      "Epoch: 274, Loss: 0.28311631083488464, Acc: 0.886840214191335, Val_Loss: 0.33700066804885864, Val_Acc: 0.862769824197018\n",
      "Epoch: 275, Loss: 0.28185224533081055, Acc: 0.8856069913535316, Val_Loss: 0.3354279398918152, Val_Acc: 0.8635672427861435\n",
      "Epoch: 276, Loss: 0.27997469902038574, Acc: 0.8863858689353021, Val_Loss: 0.33395013213157654, Val_Acc: 0.8630109042355908\n",
      "Epoch: 277, Loss: 0.27825093269348145, Acc: 0.8881847052551056, Val_Loss: 0.3353216350078583, Val_Acc: 0.8627327349603146\n",
      "Epoch: 278, Loss: 0.28021153807640076, Acc: 0.8858666172141217, Val_Loss: 0.34138453006744385, Val_Acc: 0.8634374304576812\n",
      "Epoch: 279, Loss: 0.2846987247467041, Acc: 0.8854122719580889, Val_Loss: 0.3343147039413452, Val_Acc: 0.8633261627475707\n",
      "Epoch: 280, Loss: 0.27857136726379395, Acc: 0.8875820023644498, Val_Loss: 0.33515632152557373, Val_Acc: 0.863752688969661\n",
      "Epoch: 281, Loss: 0.2796383202075958, Acc: 0.8861540601312038, Val_Loss: 0.3395368158817291, Val_Acc: 0.8639381351531785\n",
      "Epoch: 282, Loss: 0.28246384859085083, Acc: 0.8865249542177612, Val_Loss: 0.33782684803009033, Val_Acc: 0.8626214672502039\n",
      "Epoch: 283, Loss: 0.28132471442222595, Acc: 0.8852546419713021, Val_Loss: 0.33604782819747925, Val_Acc: 0.8635486981677917\n",
      "Epoch: 284, Loss: 0.2801783084869385, Acc: 0.8866547671480562, Val_Loss: 0.3350467383861542, Val_Acc: 0.863901045916475\n",
      "Epoch: 285, Loss: 0.27803030610084534, Acc: 0.8877674494077286, Val_Loss: 0.33697187900543213, Val_Acc: 0.8622134856464654\n",
      "Epoch: 286, Loss: 0.27941015362739563, Acc: 0.886269964533253, Val_Loss: 0.33696696162223816, Val_Acc: 0.8634188858393295\n",
      "Epoch: 287, Loss: 0.28021350502967834, Acc: 0.8873501935603514, Val_Loss: 0.3345620334148407, Val_Acc: 0.8645501075587865\n",
      "Epoch: 288, Loss: 0.27782753109931946, Acc: 0.8883052458332368, Val_Loss: 0.3382120132446289, Val_Acc: 0.8629923596172391\n",
      "Epoch: 289, Loss: 0.2807420790195465, Acc: 0.8864461392243678, Val_Loss: 0.3369885981082916, Val_Acc: 0.8636970551146057\n",
      "Epoch: 290, Loss: 0.2796276807785034, Acc: 0.8862885092375808, Val_Loss: 0.3383510708808899, Val_Acc: 0.8630850827089979\n",
      "Epoch: 291, Loss: 0.2808411717414856, Acc: 0.8865249542177612, Val_Loss: 0.3370698094367981, Val_Acc: 0.8640494028632891\n",
      "Epoch: 292, Loss: 0.27874183654785156, Acc: 0.8882032499594334, Val_Loss: 0.33223798871040344, Val_Acc: 0.864958089162525\n",
      "Epoch: 293, Loss: 0.27456656098365784, Acc: 0.8892324810496303, Val_Loss: 0.33671319484710693, Val_Acc: 0.8626585564869075\n",
      "Epoch: 294, Loss: 0.2792278230190277, Acc: 0.8868633950717448, Val_Loss: 0.33750641345977783, Val_Acc: 0.8634559750760329\n",
      "Epoch: 295, Loss: 0.2789444923400879, Acc: 0.8873362850321055, Val_Loss: 0.3327495753765106, Val_Acc: 0.8641606705733996\n",
      "Epoch: 296, Loss: 0.2744579017162323, Acc: 0.888977491365122, Val_Loss: 0.3364591598510742, Val_Acc: 0.862547288776797\n",
      "Epoch: 297, Loss: 0.27812546491622925, Acc: 0.8871415656366629, Val_Loss: 0.3357071578502655, Val_Acc: 0.8641235813366961\n",
      "Epoch: 298, Loss: 0.2766694128513336, Acc: 0.8879528964510072, Val_Loss: 0.33501237630844116, Val_Acc: 0.8634930643127364\n",
      "Epoch: 299, Loss: 0.27633315324783325, Acc: 0.8875912747166137, Val_Loss: 0.3365005552768707, Val_Acc: 0.8632890735108671\n",
      "Epoch: 300, Loss: 0.2779948115348816, Acc: 0.887127657108417, Val_Loss: 0.33451396226882935, Val_Acc: 0.8634559750760329\n",
      "Epoch: 301, Loss: 0.27556759119033813, Acc: 0.8882032499594334, Val_Loss: 0.33254680037498474, Val_Acc: 0.8643646613752689\n",
      "Epoch: 302, Loss: 0.27332788705825806, Acc: 0.8888384060826631, Val_Loss: 0.3371392786502838, Val_Acc: 0.8637712335880128\n",
      "Epoch: 303, Loss: 0.27728161215782166, Acc: 0.8875912747166137, Val_Loss: 0.3337404131889343, Val_Acc: 0.8636970551146057\n",
      "Epoch: 304, Loss: 0.2753327786922455, Acc: 0.8885741440459909, Val_Loss: 0.33158496022224426, Val_Acc: 0.8631036273273496\n",
      "Epoch: 305, Loss: 0.2715771496295929, Acc: 0.8902385312594172, Val_Loss: 0.3346892297267914, Val_Acc: 0.8633261627475707\n",
      "Epoch: 306, Loss: 0.27479931712150574, Acc: 0.8890377616541876, Val_Loss: 0.33416280150413513, Val_Acc: 0.8640864920999926\n",
      "Epoch: 307, Loss: 0.2757175862789154, Acc: 0.8881429796703679, Val_Loss: 0.3344598710536957, Val_Acc: 0.8621393071730584\n",
      "Epoch: 308, Loss: 0.2738201320171356, Acc: 0.8883562437701384, Val_Loss: 0.33443403244018555, Val_Acc: 0.8644388398486759\n",
      "Epoch: 309, Loss: 0.2741721272468567, Acc: 0.8897192795382368, Val_Loss: 0.3347480595111847, Val_Acc: 0.8639195905348268\n",
      "Epoch: 310, Loss: 0.2751300632953644, Acc: 0.888129071142122, Val_Loss: 0.33556777238845825, Val_Acc: 0.8633261627475707\n",
      "Epoch: 311, Loss: 0.2756541073322296, Acc: 0.8879621688031711, Val_Loss: 0.3364506661891937, Val_Acc: 0.8622505748831689\n",
      "Epoch: 312, Loss: 0.2752417027950287, Acc: 0.888703956976286, Val_Loss: 0.3320992887020111, Val_Acc: 0.8651991692010979\n",
      "Epoch: 313, Loss: 0.2720433473587036, Acc: 0.8902385312594172, Val_Loss: 0.33314329385757446, Val_Acc: 0.8640679474816408\n",
      "Epoch: 314, Loss: 0.2725963294506073, Acc: 0.889408655740745, Val_Loss: 0.336594820022583, Val_Acc: 0.8611193531637119\n",
      "Epoch: 315, Loss: 0.2754913568496704, Acc: 0.8873780106168432, Val_Loss: 0.3347097337245941, Val_Acc: 0.8639381351531785\n",
      "Epoch: 316, Loss: 0.27355173230171204, Acc: 0.8897702774751385, Val_Loss: 0.3311079442501068, Val_Acc: 0.8639937690082338\n",
      "Epoch: 317, Loss: 0.27028074860572815, Acc: 0.8906511509307123, Val_Loss: 0.33188506960868835, Val_Acc: 0.8632705288925154\n",
      "Epoch: 318, Loss: 0.2710683047771454, Acc: 0.8896219198405155, Val_Loss: 0.3375736474990845, Val_Acc: 0.8629552703805355\n",
      "Epoch: 319, Loss: 0.2752384841442108, Acc: 0.8884489672917777, Val_Loss: 0.33300894498825073, Val_Acc: 0.8636970551146057\n",
      "Epoch: 320, Loss: 0.27231574058532715, Acc: 0.8899232712858435, Val_Loss: 0.33206331729888916, Val_Acc: 0.8638083228247163\n",
      "Epoch: 321, Loss: 0.27022692561149597, Acc: 0.8899093627575976, Val_Loss: 0.3351086974143982, Val_Acc: 0.863678510496254\n",
      "Epoch: 322, Loss: 0.2729099988937378, Acc: 0.888977491365122, Val_Loss: 0.33476927876472473, Val_Acc: 0.8638639566797716\n",
      "Epoch: 323, Loss: 0.2732294499874115, Acc: 0.8886251419828926, Val_Loss: 0.3336721658706665, Val_Acc: 0.8631778058007566\n",
      "Epoch: 324, Loss: 0.2714504301548004, Acc: 0.8897378242425648, Val_Loss: 0.3321303427219391, Val_Acc: 0.8634188858393295\n",
      "Epoch: 325, Loss: 0.2692563533782959, Acc: 0.8908597788544009, Val_Loss: 0.3335506021976471, Val_Acc: 0.8637155997329575\n",
      "Epoch: 326, Loss: 0.2718588709831238, Acc: 0.8893901110364172, Val_Loss: 0.3373686969280243, Val_Acc: 0.8621207625547066\n",
      "Epoch: 327, Loss: 0.2743997871875763, Acc: 0.8874290085537448, Val_Loss: 0.3355261981487274, Val_Acc: 0.863678510496254\n",
      "Epoch: 328, Loss: 0.2726387679576874, Acc: 0.8893344769234336, Val_Loss: 0.3369961678981781, Val_Acc: 0.8636043320228469\n",
      "Epoch: 329, Loss: 0.2740449607372284, Acc: 0.8880919817334663, Val_Loss: 0.3393356502056122, Val_Acc: 0.8619724056078926\n",
      "Epoch: 330, Loss: 0.276820570230484, Acc: 0.887850900577204, Val_Loss: 0.34007734060287476, Val_Acc: 0.8629552703805355\n",
      "Epoch: 331, Loss: 0.27671197056770325, Acc: 0.8874475532580728, Val_Loss: 0.3410862386226654, Val_Acc: 0.8627883688153698\n",
      "Epoch: 332, Loss: 0.2774386703968048, Acc: 0.8875634576601219, Val_Loss: 0.33662959933280945, Val_Acc: 0.8607855500333803\n",
      "Epoch: 333, Loss: 0.272685706615448, Acc: 0.888416514059204, Val_Loss: 0.3321790099143982, Val_Acc: 0.8641977598101032\n",
      "Epoch: 334, Loss: 0.26879215240478516, Acc: 0.8907531468045157, Val_Loss: 0.3342973291873932, Val_Acc: 0.8640864920999926\n",
      "Epoch: 335, Loss: 0.27024567127227783, Acc: 0.889983541574909, Val_Loss: 0.3324020802974701, Val_Acc: 0.8620651286996514\n",
      "Epoch: 336, Loss: 0.26915261149406433, Acc: 0.8894642898537286, Val_Loss: 0.33454596996307373, Val_Acc: 0.8643832059936206\n",
      "Epoch: 337, Loss: 0.26978400349617004, Acc: 0.8908319617979091, Val_Loss: 0.33395248651504517, Val_Acc: 0.8641050367183444\n",
      "Epoch: 338, Loss: 0.26984402537345886, Acc: 0.8902153503790073, Val_Loss: 0.3377798795700073, Val_Acc: 0.8613047993472295\n",
      "Epoch: 339, Loss: 0.27462130784988403, Acc: 0.8874336447298269, Val_Loss: 0.3429161608219147, Val_Acc: 0.8627327349603146\n",
      "Epoch: 340, Loss: 0.27738097310066223, Acc: 0.8877071791186629, Val_Loss: 0.3351977467536926, Val_Acc: 0.8631592611824048\n",
      "Epoch: 341, Loss: 0.2703286111354828, Acc: 0.8907948723892534, Val_Loss: 0.33365586400032043, Val_Acc: 0.862547288776797\n",
      "Epoch: 342, Loss: 0.26980507373809814, Acc: 0.8899510883423353, Val_Loss: 0.3350241184234619, Val_Acc: 0.8647540983606558\n",
      "Epoch: 343, Loss: 0.26963570713996887, Acc: 0.8900716289204664, Val_Loss: 0.33390405774116516, Val_Acc: 0.8627327349603146\n",
      "Epoch: 344, Loss: 0.26863929629325867, Acc: 0.8905723359373189, Val_Loss: 0.33295199275016785, Val_Acc: 0.8640679474816408\n",
      "Epoch: 345, Loss: 0.2685295045375824, Acc: 0.89097568325645, Val_Loss: 0.33460941910743713, Val_Acc: 0.8642719382835101\n",
      "Epoch: 346, Loss: 0.26901641488075256, Acc: 0.8913141241104338, Val_Loss: 0.33712857961654663, Val_Acc: 0.862547288776797\n",
      "Epoch: 347, Loss: 0.27133938670158386, Acc: 0.8892185725213844, Val_Loss: 0.33863335847854614, Val_Acc: 0.8618055040427268\n",
      "Epoch: 348, Loss: 0.27239876985549927, Acc: 0.8882264308398433, Val_Loss: 0.33537596464157104, Val_Acc: 0.8643461167569172\n",
      "Epoch: 349, Loss: 0.27061572670936584, Acc: 0.8901782609703517, Val_Loss: 0.3323116600513458, Val_Acc: 0.8644573844670277\n",
      "Epoch: 350, Loss: 0.2665214240550995, Acc: 0.8923201743202207, Val_Loss: 0.33455589413642883, Val_Acc: 0.8629552703805355\n",
      "Epoch: 351, Loss: 0.26843178272247314, Acc: 0.8905027932960894, Val_Loss: 0.3377443850040436, Val_Acc: 0.8621763964097618\n",
      "Epoch: 352, Loss: 0.2713862359523773, Acc: 0.8885695078699088, Val_Loss: 0.3369773030281067, Val_Acc: 0.8636414212595505\n",
      "Epoch: 353, Loss: 0.2707427442073822, Acc: 0.890270984491991, Val_Loss: 0.335090696811676, Val_Acc: 0.8634930643127364\n",
      "Epoch: 354, Loss: 0.26841428875923157, Acc: 0.890841234150073, Val_Loss: 0.33941584825515747, Val_Acc: 0.8625101995400934\n",
      "Epoch: 355, Loss: 0.2738001346588135, Acc: 0.888133707318204, Val_Loss: 0.3444514870643616, Val_Acc: 0.8614902455307469\n",
      "Epoch: 356, Loss: 0.27619433403015137, Acc: 0.8880131667400728, Val_Loss: 0.33934035897254944, Val_Acc: 0.8633632519842742\n",
      "Epoch: 357, Loss: 0.2723540961742401, Acc: 0.8892324810496303, Val_Loss: 0.33741384744644165, Val_Acc: 0.8626771011052593\n",
      "Epoch: 358, Loss: 0.27057042717933655, Acc: 0.8896358283687614, Val_Loss: 0.3370872735977173, Val_Acc: 0.8641050367183444\n",
      "Epoch: 359, Loss: 0.27076825499534607, Acc: 0.8891073042954172, Val_Loss: 0.3394640386104584, Val_Acc: 0.8613418885839329\n",
      "Epoch: 360, Loss: 0.2714405655860901, Acc: 0.8890655787106795, Val_Loss: 0.33692312240600586, Val_Acc: 0.8642904829018618\n",
      "Epoch: 361, Loss: 0.2694703936576843, Acc: 0.8909525023760403, Val_Loss: 0.33730438351631165, Val_Acc: 0.8615458793858023\n",
      "Epoch: 362, Loss: 0.27026116847991943, Acc: 0.8894318366211549, Val_Loss: 0.33802327513694763, Val_Acc: 0.8613233439655812\n",
      "Epoch: 363, Loss: 0.27039381861686707, Acc: 0.8895106516145483, Val_Loss: 0.3366177976131439, Val_Acc: 0.8641792151917513\n",
      "Epoch: 364, Loss: 0.26788330078125, Acc: 0.8909154129673845, Val_Loss: 0.33314263820648193, Val_Acc: 0.8632519842741636\n",
      "Epoch: 365, Loss: 0.26599952578544617, Acc: 0.8919446440575813, Val_Loss: 0.3331892788410187, Val_Acc: 0.8614717009123952\n",
      "Epoch: 366, Loss: 0.26517799496650696, Acc: 0.8928347898653191, Val_Loss: 0.33407166600227356, Val_Acc: 0.8647540983606558\n",
      "Epoch: 367, Loss: 0.26564735174179077, Acc: 0.8926678875263683, Val_Loss: 0.3341762125492096, Val_Acc: 0.8623062087382242\n",
      "Epoch: 368, Loss: 0.2662160098552704, Acc: 0.891833375831614, Val_Loss: 0.33604034781455994, Val_Acc: 0.8618796825161338\n",
      "Epoch: 369, Loss: 0.26724332571029663, Acc: 0.8920234590509748, Val_Loss: 0.33540186285972595, Val_Acc: 0.8641792151917513\n",
      "Epoch: 370, Loss: 0.2668743431568146, Acc: 0.8916432926122534, Val_Loss: 0.33564624190330505, Val_Acc: 0.8634930643127364\n",
      "Epoch: 371, Loss: 0.26760783791542053, Acc: 0.8915737499710239, Val_Loss: 0.3368980288505554, Val_Acc: 0.860804094651732\n",
      "Epoch: 372, Loss: 0.26765453815460205, Acc: 0.890711421219778, Val_Loss: 0.3356545567512512, Val_Acc: 0.8634559750760329\n",
      "Epoch: 373, Loss: 0.2664168179035187, Acc: 0.891698926725237, Val_Loss: 0.3331294357776642, Val_Acc: 0.8637897782063645\n",
      "Epoch: 374, Loss: 0.2641224265098572, Acc: 0.8924128978418601, Val_Loss: 0.33304107189178467, Val_Acc: 0.8635486981677917\n",
      "Epoch: 375, Loss: 0.2640725076198578, Acc: 0.8924546234265978, Val_Loss: 0.3349321782588959, Val_Acc: 0.8621949410281137\n",
      "Epoch: 376, Loss: 0.2658499479293823, Acc: 0.8912074920605485, Val_Loss: 0.33596885204315186, Val_Acc: 0.8633817966026259\n",
      "Epoch: 377, Loss: 0.265608012676239, Acc: 0.8917313799578108, Val_Loss: 0.33659055829048157, Val_Acc: 0.8631592611824048\n",
      "Epoch: 378, Loss: 0.26774877309799194, Acc: 0.8914485732168108, Val_Loss: 0.3384625017642975, Val_Acc: 0.8610822639270084\n",
      "Epoch: 379, Loss: 0.26811322569847107, Acc: 0.8903915250701222, Val_Loss: 0.3368358314037323, Val_Acc: 0.8623062087382242\n",
      "Epoch: 380, Loss: 0.2665361166000366, Acc: 0.8919678249379911, Val_Loss: 0.336412638425827, Val_Acc: 0.8632519842741636\n",
      "Epoch: 381, Loss: 0.26666319370269775, Acc: 0.8914022114559911, Val_Loss: 0.33484941720962524, Val_Acc: 0.8636043320228469\n",
      "Epoch: 382, Loss: 0.2652643918991089, Acc: 0.8925288022439092, Val_Loss: 0.33698180317878723, Val_Acc: 0.861638602477561\n",
      "Epoch: 383, Loss: 0.2654915750026703, Acc: 0.8918797375924338, Val_Loss: 0.3368287980556488, Val_Acc: 0.8637897782063645\n",
      "Epoch: 384, Loss: 0.2673526406288147, Acc: 0.891272398525696, Val_Loss: 0.34048786759376526, Val_Acc: 0.8626029226318522\n",
      "Epoch: 385, Loss: 0.2692406475543976, Acc: 0.890117990681286, Val_Loss: 0.3398071825504303, Val_Acc: 0.8622876641198725\n",
      "Epoch: 386, Loss: 0.26974406838417053, Acc: 0.8898259115881221, Val_Loss: 0.34061503410339355, Val_Acc: 0.8610822639270084\n",
      "Epoch: 387, Loss: 0.2686507999897003, Acc: 0.8900716289204664, Val_Loss: 0.33967095613479614, Val_Acc: 0.862547288776797\n",
      "Epoch: 388, Loss: 0.26897820830345154, Acc: 0.8904286144787779, Val_Loss: 0.3400208652019501, Val_Acc: 0.8618055040427268\n",
      "Epoch: 389, Loss: 0.2687883973121643, Acc: 0.8903219824288926, Val_Loss: 0.33971211314201355, Val_Acc: 0.8615087901490988\n",
      "Epoch: 390, Loss: 0.2687966823577881, Acc: 0.8899603606944991, Val_Loss: 0.34139785170555115, Val_Acc: 0.8610451746903048\n",
      "Epoch: 391, Loss: 0.26898467540740967, Acc: 0.8905074294721713, Val_Loss: 0.3431049585342407, Val_Acc: 0.8624360210666865\n",
      "Epoch: 392, Loss: 0.27153778076171875, Acc: 0.8888569507869909, Val_Loss: 0.34092453122138977, Val_Acc: 0.861564424004154\n",
      "Epoch: 393, Loss: 0.2688066065311432, Acc: 0.890270984491991, Val_Loss: 0.33730748295783997, Val_Acc: 0.8612862547288777\n",
      "Epoch: 394, Loss: 0.265830397605896, Acc: 0.8913929391038271, Val_Loss: 0.3356477618217468, Val_Acc: 0.863752688969661\n",
      "Epoch: 395, Loss: 0.2633610665798187, Acc: 0.8933957671712371, Val_Loss: 0.3345921039581299, Val_Acc: 0.8629552703805355\n",
      "Epoch: 396, Loss: 0.26240235567092896, Acc: 0.8939011103641716, Val_Loss: 0.33341309428215027, Val_Acc: 0.863066538090646\n",
      "Epoch: 397, Loss: 0.2615879774093628, Acc: 0.8936739377361552, Val_Loss: 0.33516305685043335, Val_Acc: 0.8633632519842742\n",
      "Epoch: 398, Loss: 0.2625836730003357, Acc: 0.8935487609819421, Val_Loss: 0.33703887462615967, Val_Acc: 0.8631592611824048\n",
      "Epoch: 399, Loss: 0.26495665311813354, Acc: 0.8919121908250075, Val_Loss: 0.33619192242622375, Val_Acc: 0.8632519842741636\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 400\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss,accuracy = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    val_accuracy = 0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(testing_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            val_accuracy += (torch.argmax(voutputs, 1) == torch.argmax(vlabels, 1)).sum().item()\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    val_accuracy /= len(X_test_tensor)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss), 'ACC train {} valid {}'.format(accuracy, val_accuracy))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('Training vs. Validation Accuracy',\n",
    "                    { 'Training' : accuracy, 'Validation' : val_accuracy },)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([197977])\n"
     ]
    }
   ],
   "source": [
    "model_ann.eval()\n",
    "y_pred = torch.argmax(model_ann(X_train_tensor), 1)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model = model_ann\n",
    "model.load_state_dict(torch.load('../model/model_ann.pth'))\n",
    "model.eval()\n",
    "y_pred = model(X_test_tensor)\n",
    "_, predicted = torch.max(y_pred, 1)\n",
    "accuracy = (y_test_ohe_tensor == predicted).sum().item() / y_test_ohe_tensor.size(0)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[1])\n",
    "print(torch.argmax(y_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
